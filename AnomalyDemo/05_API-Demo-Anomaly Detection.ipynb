{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"//tiny.cc/devnetlogo\" alt=\"Logo\">\n",
    "    \n",
    "# Cisco Connect 2020 - Anomaly Detection Click-through Demo\n",
    "\n",
    "<img src='./Image2.png' style=\"width: 500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artifical Intelligence & Machine Learning in Cisco\n",
    "https://www.cisco.com/c/en/us/solutions/artificial-intelligence.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this click-through demo, you will build a machine learning model and\n",
    "apply it to detect failing servers on a network.\n",
    "\n",
    "We start from two inputs (throughput and latency) to identify the normal vs anomaly. And we expand the method into multiple inputs scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import All Required Libraries\n",
    "##### How to execute this code: Highlight this cell, then press \"Shift+Return(Enter)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for manipulating directory paths\n",
    "import os\n",
    "\n",
    "# vector computation and dataframe for python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting library\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# tells matplotlib to embed plots within the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This imports the modules and information we need to build anomaly detection model, no output expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Visulization\n",
    "- Latency: The time taken for a packet to be transferred across a network. You can measure this as one-way to its destination or as a round trip.\n",
    "- Throughput: The quantity of data being sent and received within a unit of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import two dimensions data train set and convert from pandas dataframe to numpy array\n",
    "train_two_dimension = pd.read_csv('./data/train_two_dimensions.csv')\n",
    "train_two_dimension = np.array(train_two_dimension)\n",
    "\n",
    "X_train_two_dimension = train_two_dimension[:,:-1]\n",
    "y_train_two_dimension = train_two_dimension[:,-1]\n",
    "\n",
    "### import test set two dimensions data and convert from pandas dataframe to numpy array\n",
    "test_two_dimension = pd.read_csv('./data/test_two_dimensions.csv')\n",
    "test_two_dimension = np.array(test_two_dimension)\n",
    "\n",
    "X_test_two_dimension = test_two_dimension[:,[0,1]]\n",
    "y_test_two_dimension = test_two_dimension[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those code above loads data. No output expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "def plotData(myX, newFig=False):\n",
    "        \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8,6))\n",
    "    ax.plot(myX[:,0],myX[:,1],'b+')\n",
    "    ax.set_xlabel('Latency [ms]',fontsize=16)\n",
    "    ax.set_ylabel('Throughput [mb/s]',fontsize=16)\n",
    "    ax.grid(linestyle=\"-.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function 'plotData' above build function to plot data. No output expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotData(X_train_two_dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Gaussian Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform anomaly detection, first we fit a model to the data's distribution. Given a training set $\\{x^{(1)}, \\dots, x^{(m)} \\}$ (where $x^{(i)} \\in \\mathbb{R}^n$ ), you want to estimate the Gaussian distribution for each of the features $x_i$ . For each feature $i = 1 \\dots n$, you need to find parameters $\\mu_i$ and $\\sigma_i^2$  that fit the data in the $i^{th}$ dimension $\\{ x_i^{(1)}, \\dots, x_i^{(m)} \\}$ (the $i^{th}$ dimension of each example).\n",
    "\n",
    "The Gaussian distribution is given by\n",
    "\n",
    "$$ p\\left( x; \\mu, \\sigma^2 \\right) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{\\left(x-\\mu\\right)^2}{2\\sigma^2}},$$\n",
    "where $\\mu$ is the mean and $\\sigma^2$ is the variance.\n",
    "\n",
    "<img src='./Image.png' style=\"width: 500px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaus(myX, mymu, mysig2):\n",
    "    \"\"\"\n",
    "    Function to compute the gaussian return values for a feature\n",
    "    matrix, myX, given the already computed mu vector and sigma matrix.\n",
    "    If sigma is a vector, it is turned into a diagonal matrix\n",
    "    Uses a loop over rows\n",
    "    \"\"\"\n",
    "    m = myX.shape[0]\n",
    "    n = myX.shape[1]\n",
    "    if np.ndim(mysig2) == 1:\n",
    "        mysig2 = np.diag(mysig2)\n",
    "\n",
    "    norm = 1./(np.power((2*np.pi), n/2)*np.sqrt(np.linalg.det(mysig2)))\n",
    "    myinv = np.linalg.inv(mysig2)\n",
    "    myexp = np.zeros((m,1))\n",
    "    for irow in range(m):\n",
    "        xrow = myX[irow]\n",
    "        myexp[irow] = np.exp(-0.5*((xrow-mymu).T).dot(myinv).dot(xrow-mymu))\n",
    "    return norm*myexp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function 'gaus' above build the Gaussian distribution function. No output expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can estimate the parameters $\\left( \\mu_i, \\sigma_i^2 \\right)$, of the $i^{th}$ feature by using the following equations. To estimate the mean, you will use: \n",
    "\n",
    "$$ \\mu_i = \\frac{1}{m} \\sum_{j=1}^m x_i^{(j)},$$\n",
    "\n",
    "and for the variance you will use:\n",
    "\n",
    "$$ \\sigma_i^2 = \\frac{1}{m} \\sum_{j=1}^m \\left( x_i^{(j)} - \\mu_i \\right)^2.$$\n",
    "\n",
    "Your task is to complete the code in the function `estimateGaussian`. This function takes as input the data matrix `X` and should output an n-dimension vector `mu` that holds the mean for each of the $n$ features and another n-dimension vector `sigma2` that holds the variances of each of the features. You can implement this\n",
    "using a for-loop over every feature and every training example (though a vectorized implementation might be more efficient; feel free to use a vectorized implementation if you prefer). \n",
    "<a id=\"estimateGaussian\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Estimating parameters for a Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGaussianParams(myX):\n",
    "    \"\"\"\n",
    "    Function that given a feature matrix X that is (m x n)\n",
    "    returns a mean vector and a sigmasquared vector that are\n",
    "    both (n x 1) in shape.\n",
    "    This can do it either as a 1D gaussian for each feature,\n",
    "    or as a multivariate gaussian.\n",
    "    \"\"\"\n",
    "    m = myX.shape[0]\n",
    "    mu = np.mean(myX,axis=0)\n",
    "#     if not useMultivariate:\n",
    "#         sigma2 = np.sum(np.square(myX-mu),axis=0)/float(m)\n",
    "#         return mu, sigma2\n",
    "#     else:\n",
    "    sigma2 = ((myX-mu).T.dot(myX-mu))/float(m)\n",
    "    return mu, sigma2\n",
    "\n",
    "mu, sig2 = getGaussianParams(X_train_two_dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function 'getGaussianParams' is built to estimate the parameter of Gaussian distribution. No output expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Visualizing the Gaussian Probability Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotContours(mymu, mysigma2, newFig=False, useMultivariate = True):\n",
    "    delta = .5\n",
    "    myx = np.arange(-2,30,delta)\n",
    "    myy = np.arange(-2,30,delta)\n",
    "    meshx, meshy = np.meshgrid(myx, myy)\n",
    "    coord_list = [ entry.ravel() for entry in (meshx, meshy) ]\n",
    "    points = np.vstack(coord_list).T\n",
    "    myz = gaus(points, mymu, mysigma2)\n",
    "\n",
    "    myz = myz.reshape((myx.shape[0],myx.shape[0]))\n",
    "\n",
    "    if newFig: plt.figure(figsize=(8,8))\n",
    "    \n",
    "    cont_levels = [10**exp for exp in range(-20,-3,3)]\n",
    "    mycont = plt.contour(meshx, meshy, myz, levels=cont_levels)\n",
    "\n",
    "    plt.title('Gaussian Contours',fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function 'plotContours' is built to plot Contour chart. No output expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotData(X_train_two_dimension, newFig=True)\n",
    "#plotContours(*getGaussianParams(X_train_two_dimension), newFig=False)\n",
    "\n",
    "plotData(X_train_two_dimension, newFig=True)\n",
    "plotContours(*getGaussianParams(X_train_two_dimension), newFig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Selecting the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeF1(predVec, trueVec):\n",
    "    \"\"\"\n",
    "    F1 = 2 * (P*R)/(P+R)\n",
    "    where P is precision, R is recall\n",
    "    Precision = \"of all predicted y=1, what fraction had true y=1\"\n",
    "    Recall = \"of all true y=1, what fraction predicted y=1?\n",
    "    Note predictionVec and trueLabelVec should be boolean vectors.\n",
    "    \"\"\"\n",
    "    \n",
    "    P, R = 0., 0.\n",
    "    if float(np.sum(predVec)):\n",
    "        P = np.sum([int(trueVec[x]) for x in range(predVec.shape[0]) \\\n",
    "                    if predVec[x]]) / float(np.sum(predVec))\n",
    "    if float(np.sum(trueVec)):\n",
    "        R = np.sum([int(predVec[x]) for x in range(trueVec.shape[0]) \\\n",
    "                    if trueVec[x]]) / float(np.sum(trueVec))\n",
    "        \n",
    "    return 2*P*R/(P+R) if (P+R) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectThreshold(myY, gaussian):\n",
    "    \"\"\"\n",
    "    Function to select the best epsilon value from the CV set\n",
    "    by looping over possible epsilon values and computing the F1\n",
    "    score for each.\n",
    "    \"\"\"\n",
    "    # Make a list of possible epsilon values\n",
    "    nsteps = 1000\n",
    "    epses = np.linspace(np.min(gaussian),np.max(gaussian),nsteps)\n",
    "    \n",
    "    # Compute the F1 score for each epsilon value, and store the best \n",
    "    # F1 score (and corresponding best epsilon)\n",
    "    bestF1, bestEps = 0, 0\n",
    "    trueVec = (myY == 1).flatten()\n",
    "    for eps in epses:\n",
    "        predVec = gaussian < eps\n",
    "        thisF1 = computeF1(predVec, trueVec)\n",
    "        if thisF1 > bestF1:\n",
    "            bestF1 = thisF1\n",
    "            bestEps = eps\n",
    "            \n",
    "    print (\"Best F1 is %f, best eps is %0.4g.\"%(bestF1,bestEps))\n",
    "    return bestF1, bestEps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function above is built to optimize the threshold for anamoly. No output is expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the gaussian parameters from the full training set,\n",
    "# figure out the p-value for each point in the CV set\n",
    "pCVs = gaus(X_train_two_dimension, mu, sig2)\n",
    "\n",
    "#You should see a value for epsilon of about 8.99e-05.\n",
    "bestF1, bestEps = selectThreshold(y_train_two_dimension,pCVs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotAnomalies(myX, myXY, mybestEps, newFig = False):\n",
    "    ps = gaus(myX, *getGaussianParams(myX))\n",
    "    anoms_pred = np.array([myX[x] for x in range(myX.shape[0]) if ps[x] <= mybestEps])\n",
    "    anoms_true = np.array([myXY[x] for x in range(myXY.shape[0]) if myXY[x,2]==1])\n",
    "    \n",
    "#     y_pred = np.array([1 if ps[x] <= mybestEps else 0 for x in range(myX.shape[0]) ])\n",
    "#     y_true = np.array([1 if myXY[x,2]==1 else 0 for x in range(myXY.shape[0]) ])\n",
    "    \n",
    "    if newFig: plt.figure(figsize=(6,4))\n",
    "    plt.scatter(anoms_true[:,0],anoms_true[:,1], s=80, facecolors='r', edgecolors='None')\n",
    "    plt.scatter(anoms_pred[:,0],anoms_pred[:,1], s=120, facecolors='b', edgecolors='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function above is built to plot anomaly. No output is expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotData(X_train_two_dimension, newFig=True)\n",
    "plotContours(mu, sig2, newFig=False)\n",
    "plotAnomalies(X_train_two_dimension, train_two_dimension, bestEps, newFig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotData(X_test_two_dimension, newFig=True)\n",
    "plotContours(mu, sig2, newFig=False)\n",
    "plotAnomalies(X_test_two_dimension, test_two_dimension, bestEps, newFig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. High dimensional dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import cross validation high dimension data and convert from pandas dataframe to numpy array\n",
    "train_high_dimension = pd.read_csv('./data/train_high_dimension.csv')\n",
    "train_high_dimension = np.array(train_high_dimension)\n",
    "\n",
    "X_train_high_dimension = train_high_dimension[:,:-1]\n",
    "y_train_high_dimension = train_high_dimension[:,-1]\n",
    "\n",
    "### import x train high dimension data and convert from pandas dataframe to numpy array\n",
    "X_test_high_dimension = pd.read_csv('./data/X_test_high_dimension.csv')\n",
    "X_test_high_dimension = np.array(X_test_high_dimension)\n",
    "\n",
    "print ('X train high dimension shape is ', X_train_high_dimension.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 7. Apply the model in the two dimentional inputs to high dimentional dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using high dimensiond train set to estimate the paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sig2 = getGaussianParams(X_train_high_dimension)\n",
    "print('Mean of each input:', mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using high dimensiond train set to optimize the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_trains = gaus(X_train_high_dimension, mu, sig2)\n",
    "bestF1, bestEps = selectThreshold(y_train_high_dimension, p_trains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Challenge for you \n",
    "### *Based on the training output of mean (mu) and variance (sig2), can you calculate the Gaussian distribution of test set?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Misssion\n",
    "# ====================== YOUR CODE HERE ======================\n",
    "### One Line Code\n",
    "p_test ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on the optimized threshold and Gaussian distribution, find out the anomaly in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anoms = [X_test_high_dimension[x] for x in range(X_test_high_dimension.shape[0]) if p_test[x] < bestEps]\n",
    "print ('# of anomalies found: ',len(anoms))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
